theme_minimal()
grid.arrange(p1, p2, nrow = 1)
# Load the ggplot2 library
library(ggplot2)
#We now further inspect the non-normalized distributions
# Plot distribution of Age
ggplot(data1, aes(x = Age)) +
geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
labs(title = "Distribution of Age", x = "Age (Years)", y = "Frequency") +
theme_minimal()
# Plot distribution of AskPrice
ggplot(data1, aes(x = AskPrice)) +
geom_histogram(bins = 20, fill = "lightcoral", color = "black") +
labs(title = "Distribution of Asking Price", x = "Price", y = "Frequency") +
theme_minimal()
# Plot distribution of kmPerYear
ggplot(data1, aes(x = kmPerYear)) +
geom_histogram(bins = 20, fill = "lightpink", color = "black") +
labs(title = "km Driven Per Year", x = "km Per Year", y = "Frequency") +
theme_minimal()
#We now view categorical data distributions
# Plot Count of Cars by Brand
ggplot(data1, aes(x = Brand)) +
geom_bar(fill = "steelblue") +
labs(title = "Count of Cars by Brand", x = "Brand", y = "Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10))  # Rotate x-axis labels for readability
# Plot Fuel Type Distribution
p1<-ggplot(data1, aes(x = FuelType)) +
geom_bar(fill = "orange") +
labs(title = "Fuel Type Distribution", x = "Fuel Type", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot Transmission Type
p2<-ggplot(data1, aes(x = Transmission)) +
geom_bar(fill = "lightgreen") +
labs(title = "Transmission Type", x = "Transmission", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot Owner Type Distribution
p3<-ggplot(data1, aes(x = Owner)) +
geom_bar(fill = "purple") +
labs(title = "Owner Type", x = "Owner Type", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
grid.arrange(p1,p2,p3,nrow=1)
#We then view some relations between numeric data
# Plot Price vs Age of Car
p1<-ggplot(data1, aes(x = Age, y = AskPrice)) +
geom_point(color = "blue") +
labs(title = "Price vs Age of Car", x = "Age (Years)", y = "Asking Price") +
theme_minimal()
# Plot Price vs km Driven
p2<-ggplot(data1, aes(x = kmDriven, y = AskPrice)) +
geom_point(color = "red") +
labs(title = "Price vs km Driven", x = "km Driven", y = "Asking Price") +
theme_minimal()
grid.arrange(p1,p2,nrow=1)
p1<-ggplot(data1, aes(x = Age, y = AskPrice)) +
geom_point(color = "blue") +
labs(title = "Price vs Age of Car", x = "km per year", y = "Asking Price") +
theme_minimal()
# Plot Price vs km Driven
p2<-ggplot(data1, aes(x = kmDriven, y = AskPrice)) +
geom_point(color = "red") +
labs(title = "Price vs km Driven", x = "posted months", y = "Asking Price") +
theme_minimal()
grid.arrange(p1,p2,nrow=1)
#After labal encoding, we now create the correlation matrix and view heat map
# Load necessary libraries
library(ggplot2)
library(reshape2)
# Create correlation matrix
cor_matrix <- cor(encoded_data, use = "complete.obs")
# Reshape the correlation matrix to long format for ggplot
cor_matrix_melted <- melt(cor_matrix)
# Create the heatmap using ggplot2
ggplot(cor_matrix_melted, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,limit=c(-1,1),space = "Lab",name = "correlation") +
labs(title = "Correlation Heatmap", x = "", y = "") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,size = 16,hjust = 1), axis.text.y = element_text(angle = 0, hjust = 1,vjust = 1,size = 16))  # Rotate axis labels
#We lastly create bar plot for correlation with ask price
# Load necessary libraries
library(ggplot2)
# Create a data frame from the correlations (excluding AskPrice)
correlations_df <- data.frame(
Variable = names(correlations),
Correlation = correlations
)
# Create bar plot using ggplot2
ggplot(correlations_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Absolute Correlation of Each Column with AskPrice", x = "Variable", y = "Correlation Coefficient") +
theme_minimal() +
theme(axis.text.x = element_text(angle =90, hjust = 1, size = 15))  # Rotate x-axis labels
#We then visualize our newly created features
p1<-ggplot(data1,aes(y=kmPerYear))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Km Driven") +
theme_minimal()
p2<-ggplot(data1,aes(y=PostedMonths))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Age") +
theme_minimal()
grid.arrange(p1, p2, nrow = 1)
#We then view some relations between numeric data
# Plot Price vs Age of Car
p1<-ggplot(data1, aes(x = Age, y = AskPrice)) +
geom_point(color = "blue") +
labs(title = "Price vs Age of Car", x = "Age (Years)", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
# Plot Price vs km Driven
p2<-ggplot(data1, aes(x = kmDriven, y = AskPrice)) +
geom_point(color = "red") +
labs(title = "Price vs km Driven", x = "km Driven", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
grid.arrange(p1,p2,nrow=1)
#We visualize the numeric data in our data frame
library(gridExtra)
library(dplyr)
p1<-ggplot(data,aes(y=data$kmDriven))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Km Driven", y = "") +
theme_minimal()
p2<-ggplot(data,aes(y=data$Age))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Age", y = "") +
theme_minimal()
p3<-ggplot(data,aes(y=data$AskPrice))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Ask Price", y = "") +
theme_minimal()
grid.arrange(p1, p2, p3, nrow = 1)
#We then visualize our newly created features
p1<-ggplot(data1,aes(y=kmPerYear))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Km Driven") +
theme_minimal()
p2<-ggplot(data1,aes(y=PostedMonths))+geom_boxplot(fill="steelblue",color="black",outlier.color = "red")+labs(title = "Age") +
theme_minimal()
grid.arrange(p1, p2, nrow = 1)
# Load the ggplot2 library
library(ggplot2)
#We now further inspect the non-normalized distributions
# Plot distribution of Age
ggplot(data1, aes(x = Age)) +
geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
labs(title = "Distribution of Age", x = "Age (Years)", y = "Frequency") +
theme_minimal()
# Plot distribution of AskPrice
ggplot(data1, aes(x = AskPrice)) +
geom_histogram(bins = 20, fill = "lightcoral", color = "black") +
labs(title = "Distribution of Asking Price", x = "Price", y = "Frequency") +
theme_minimal()
# Plot distribution of kmPerYear
ggplot(data1, aes(x = kmPerYear)) +
geom_histogram(bins = 20, fill = "lightpink", color = "black") +
labs(title = "km Driven Per Year", x = "km Per Year", y = "Frequency") +
theme_minimal()
#We now view categorical data distributions
# Plot Count of Cars by Brand
ggplot(data1, aes(x = Brand)) +
geom_bar(fill = "steelblue") +
labs(title = "Count of Cars by Brand", x = "Brand", y = "Count") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10))  # Rotate x-axis labels for readability
# Plot Fuel Type Distribution
p1<-ggplot(data1, aes(x = FuelType)) +
geom_bar(fill = "orange") +
labs(title = "Fuel Type Distribution", x = "Fuel Type", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot Transmission Type
p2<-ggplot(data1, aes(x = Transmission)) +
geom_bar(fill = "lightgreen") +
labs(title = "Transmission Type", x = "Transmission", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Plot Owner Type Distribution
p3<-ggplot(data1, aes(x = Owner)) +
geom_bar(fill = "purple") +
labs(title = "Owner Type", x = "Owner Type", y = "Count") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
grid.arrange(p1,p2,p3,nrow=1)
#We then view some relations between numeric data
# Plot Price vs Age of Car
p1<-ggplot(data1, aes(x = Age, y = AskPrice)) +
geom_point(color = "blue") +
labs(title = "Price vs Age of Car", x = "Age (Years)", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
# Plot Price vs km Driven
p2<-ggplot(data1, aes(x = kmDriven, y = AskPrice)) +
geom_point(color = "red") +
labs(title = "Price vs km Driven", x = "km Driven", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
grid.arrange(p1,p2,nrow=1)
p1<-ggplot(data1, aes(x = Age, y = AskPrice)) +
geom_point(color = "blue") +
labs(title = "Price vs Age of Car", x = "km per year", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
# Plot Price vs km Driven
p2<-ggplot(data1, aes(x = kmDriven, y = AskPrice)) +
geom_point(color = "red") +
labs(title = "Price vs km Driven", x = "posted months", y = "Asking Price") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
grid.arrange(p1,p2,nrow=1)
#After labal encoding, we now create the correlation matrix and view heat map
# Load necessary libraries
library(ggplot2)
library(reshape2)
# Create correlation matrix
cor_matrix <- cor(encoded_data, use = "complete.obs")
# Reshape the correlation matrix to long format for ggplot
cor_matrix_melted <- melt(cor_matrix)
# Create the heatmap using ggplot2
ggplot(cor_matrix_melted, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,limit=c(-1,1),space = "Lab",name = "correlation") +
labs(title = "Correlation Heatmap", x = "", y = "") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,size = 16,hjust = 1), axis.text.y = element_text(angle = 0, hjust = 1,vjust = 1,size = 16))  # Rotate axis labels
#We lastly create bar plot for correlation with ask price
# Load necessary libraries
library(ggplot2)
# Create a data frame from the correlations (excluding AskPrice)
correlations_df <- data.frame(
Variable = names(correlations),
Correlation = correlations
)
# Create bar plot using ggplot2
ggplot(correlations_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Absolute Correlation of Each Column with AskPrice", x = "Variable", y = "Correlation Coefficient") +
theme_minimal() +
theme(axis.text.x = element_text(angle =90, hjust = 1, size = 15))  # Rotate x-axis labels
#We differentiate between luxurious and regular brands
luxury_brands <- c("BMW", "Mercedes-Benz", "Audi","Tesla","Porsche","Volvo","Lexus","Ferrari", "Lamborghini","Aston Martin","Bentley","Ford","Rolls-Royce" ,"Land Rover")
data1$isLuxury <- data1$Brand %in% luxury_brands
#We extract how many Km were driven per year
data1$kmPerYear <- data1$kmDriven / data1$Age
data1$kmPerYear[is.na(data1$kmPerYear)] <- 0
data1$kmPerYear[is.infinite(data1$kmPerYear)] <- data1$kmDriven[is.infinite(data1$kmPerYear)]
sum(data1$kmPerYear== "")
# Check the levels of the factor
levels(data1$PostedDate)
levels(data1$PostedDate)[1]
# Ensure PostedDate is in Date format (if it is not already)
data1$PostedDate <- as.Date(data1$PostedDate, format = "%Y-%m-%d")  # Adjust format if necessary
# Now, create the PostedMonths variable
data1$PostedMonths <- (as.integer(format(data1$PostedDate, "%Y")) - 2023) * 12 + (as.integer(format(data1$PostedDate, "%m")) - 11)
# Check the result
head(data1$PostedMonths)
#We combine both brand and model into 1 feature
data1$Brand.model <-paste0(data1$Brand,"-",data1$model)
# Save data with features
#After some visualization, we label encode data
encoded_data <- data1
for (col in names(encoded_data)) if (!is.numeric(encoded_data[[col]])) encoded_data[[col]] <- as.numeric(as.factor(encoded_data[[col]]))
encoded_data <- subset(encoded_data, select = -c(Year, PostedDate, PostedYear))
#After Completing Visualization Step:
#We apply log transormation on km per Year and Ask Price
encoded_data$LogkmPerYear = ifelse(encoded_data$kmPerYear == 0,0,log(encoded_data$kmPerYear))
encoded_data$LogAskPrice = ifelse(encoded_data$AskPrice==0,0,log(encoded_data$AskPrice))
#We now look at the correlation with log ask price
encoded_data$kmPerYear <- NULL
encoded_data$AskPrice <- NULL
correlations <- sapply(encoded_data, function(col) cor(col, encoded_data$LogAskPrice, use="pairwise.complete.obs"))
correlations <- abs(correlations[names(correlations) != "LogAskPrice"])
# Convert to a data frame for ggplot
correlation_df <- data.frame(
Variable = names(correlations),
Correlation = correlations
)
# Plot using ggplot2
library(ggplot2)
ggplot(correlation_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Absolute Correlation of Each Column with LogAskPrice", y = "Correlation Coefficient") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10))  # Rotate axis labels and adjust size
#We filter out features with low correlation with log ask price
encoded_data <- subset(encoded_data, select = -c(Brand, model, PostedMonths, Brand.model))
write.csv(data1, "feature_extraction_data.csv", row.names=FALSE)
#We differentiate between luxurious and regular brands
luxury_brands <- c("BMW", "Mercedes-Benz", "Audi","Tesla","Porsche","Volvo","Lexus","Ferrari", "Lamborghini","Aston Martin","Bentley","Ford","Rolls-Royce" ,"Land Rover")
data1$isLuxury <- data1$Brand %in% luxury_brands
#We extract how many Km were driven per year
data1$kmPerYear <- data1$kmDriven / data1$Age
data1$kmPerYear[is.na(data1$kmPerYear)] <- 0
data1$kmPerYear[is.infinite(data1$kmPerYear)] <- data1$kmDriven[is.infinite(data1$kmPerYear)]
sum(data1$kmPerYear== "")
# Check the levels of the factor
levels(data1$PostedDate)
levels(data1$PostedDate)[1]
# Ensure PostedDate is in Date format (if it is not already)
data1$PostedDate <- as.Date(data1$PostedDate, format = "%Y-%m-%d")  # Adjust format if necessary
# Now, create the PostedMonths variable
data1$PostedMonths <- (as.integer(format(data1$PostedDate, "%Y")) - 2023) * 12 + (as.integer(format(data1$PostedDate, "%m")) - 11)
# Check the result
head(data1$PostedMonths)
#We combine both brand and model into 1 feature
data1$Brand.model <-paste0(data1$Brand,"-",data1$model)
# Save data with features
#After some visualization, we label encode data
encoded_data <- data1
for (col in names(encoded_data)) if (!is.numeric(encoded_data[[col]])) encoded_data[[col]] <- as.numeric(as.factor(encoded_data[[col]]))
encoded_data <- subset(encoded_data, select = -c(Year, PostedDate, PostedYear))
#After Completing Visualization Step:
#We apply log transormation on km per Year and Ask Price
encoded_data$LogkmPerYear = ifelse(encoded_data$kmPerYear == 0,0,log(encoded_data$kmPerYear))
encoded_data$LogAskPrice = ifelse(encoded_data$AskPrice==0,0,log(encoded_data$AskPrice))
#We now look at the correlation with log ask price
encoded_data$kmPerYear <- NULL
encoded_data$AskPrice <- NULL
correlations <- sapply(encoded_data, function(col) cor(col, encoded_data$LogAskPrice, use="pairwise.complete.obs"))
correlations <- abs(correlations[names(correlations) != "LogAskPrice"])
# Convert to a data frame for ggplot
correlation_df <- data.frame(
Variable = names(correlations),
Correlation = correlations
)
# Plot using ggplot2
library(ggplot2)
ggplot(correlation_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Absolute Correlation of Each Column with LogAskPrice", y = "Correlation Coefficient") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10))  # Rotate axis labels and adjust size
#We filter out features with low correlation with log ask price
encoded_data <- subset(encoded_data, select = -c(Brand, model, PostedMonths, Brand.model))
write.csv(data1, "feature_extraction_data.csv", row.names=FALSE)
## Load Required Libraries ##
library(xgboost)
library(caret)
## Split the data to train(80%) and test(20%) ##
#set.seed(123)
trainIndex <- sample(1:nrow(encoded_data), 0.8 * nrow(encoded_data))
trainData <- encoded_data[trainIndex, ]  # Training set
testData <- encoded_data[-trainIndex, ]  # Test set
trainLabel <- encoded_data$LogAskPrice[trainIndex]
testLabel <- encoded_data$LogAskPrice[-trainIndex]
## Exclude the logAskPrice column ##
featuresTrain <- trainData[, !colnames(trainData) %in% "LogAskPrice"]
featuresTest <- testData[, !colnames(testData) %in% "LogAskPrice"]
trainMatrix <- as.matrix(featuresTrain)
testMatrix <- as.matrix(featuresTest)
# Ensure trainLabel is numeric
train_label <- as.numeric(trainLabel)
# Verify data dimensions
if (nrow(trainMatrix) != length(trainLabel)) {
stop("Mismatch between rows in trainData and length of trainLabel")
}
## Applying XGboost data model ##
XGB_model <- xgboost(data = trainMatrix,
label = trainLabel,
nrounds = 100,
objective = "reg:squarederror",
verbose = 0)
## Predict the Target col ##
predictions <- predict(XGB_model, testMatrix)
## calculate the residuals (rmse) ##
rmse <- sqrt(mean((predictions - testLabel)^2))
mae <- mean(abs(predictions - testLabel))
ss_total <- sum((testLabel - mean(testLabel))^2)
ss_residual <- sum((testLabel - predictions)^2)
r_squared <- 1 - (ss_residual / ss_total)
print(paste("RMSE:", format(rmse, scientific = FALSE)))
print(paste("MAE:", format(mae, scientific = FALSE)))
print(paste("R-squared:", format(r_squared, scientific = FALSE)))
## Calculate MAPE and Accuracy ##
mape <- mean(abs((testLabel - predictions) / testLabel)) * 100
accuracy <- 100 - mape
cat("\n XGboost Accuracy (%): ", accuracy, "\n")
library(dplyr)
library(randomForest)
library(caret)
# Load  featured dataset
data_frame <- read.csv("feature_extraction_data.csv")
head(data_frame)
# Step 1: Train-Test Split
set.seed(123)
n <- nrow(data_frame)
train_indices <- sample(1:n, size = 0.8 * n)
train_data <- data_frame[train_indices, ]
test_data <- data_frame[-train_indices, ]
# Step 2: Train Random Forest Model
rf_model <- randomForest(AskPrice ~ ., data = train_data,ntree=300,mtry=9, importance = TRUE)
library(dplyr)
library(randomForest)
library(caret)
# Load  featured dataset
data_frame <- read.csv("feature_extraction_data.csv")
head(data_frame)
# Step 1: Train-Test Split
set.seed(123)
n <- nrow(data_frame)
train_indices <- sample(1:n, size = 0.8 * n)
train_data <- data_frame[train_indices, ]
test_data <- data_frame[-train_indices, ]
# Step 2: Train Random Forest Model
rf_model <- randomForest(AskPrice ~ ., data = train_data,ntree=300,mtry=9, importance = TRUE)
# Step 3: Make Predictions
predictions_rf <- predict(rf_model, newdata = test_data)
# Step 4: Model Evaluation
evaluate <- function(actual, predicted) {
mae <- mean(abs(actual - predicted))  # Mean Absolute Error
mse <- mean((actual - predicted)^2)  # Mean Squared Error
r2 <- cor(actual, predicted)^2       # Coefficient of Determination (R²)
mae <- format(mae, scientific = FALSE, digits = 2)
mse <- format(mse, scientific = FALSE, digits = 2)
r2 <- format(r2, scientific = FALSE, digits = 3)
return(c(MAE = mae, MSE = mse, R2 = r2))
}
# Actual values from test set
actual_values <- test_data$AskPrice
# Evaluate Random Forest Model
rf_metrics <- evaluate(actual_values, predictions_rf)
cat("\nRandom Forest Evaluation Metrics:\n")
cat("MAE: ", rf_metrics["MAE"], "\n")
cat("MSE: ", rf_metrics["MSE"], "\n")
cat("R²: ", rf_metrics["R2"], "\n")
# Accuracy Calculation (using MAPE)
calculate_accuracy <- function(actual, predicted) {
mape <- mean(abs((actual - predicted) / actual)) * 100  # Mean Absolute Percentage Error
accuracy <- 100 - mape  # Accuracy as 100 - MAPE
return(accuracy)
}
# Calculate Random Forest Accuracy
rf_accuracy <- calculate_accuracy(actual_values, predictions_rf)
cat("\nRandom Forest Accuracy (%): ", rf_accuracy, "\n")
# Step 5: Visualization
# 1. Actual vs Predicted Scatter Plot
library(ggplot2)
library(scales)  # Load scales package for formatting
# Creating a dataframe for ggplot
df <- data.frame(Actual = actual_values, Predicted = predictions_rf)
ggplot(df, aes(x = Actual, y = Predicted)) +
geom_point(color = "blue", alpha = 0.6) +  # Scatter points
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed", size = 1) +  # Reference line y = x
labs(title = "Actual vs Predicted Prices (Random Forest)",
x = "Actual Prices",
y = "Predicted Prices") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
# 2. Residual Plot
library(ggplot2)
# Creating a dataframe for ggplot
df_residuals <- data.frame(Predicted = predictions_rf, Residuals = residuals_rf)
# Residual Plot using ggplot2
ggplot(df_residuals, aes(x = Predicted, y = Residuals)) +
geom_point(color = "green", alpha = 0.6) +  # Scatter points
geom_hline(yintercept = 0, color = "red", linetype = "dashed", size = 1) +  # Reference line at residual = 0
labs(title = "Residual Plot (Random Forest)",
x = "Predicted Prices",
y = "Residuals") +
scale_x_continuous(labels = comma) +  # Format x-axis numbers
scale_y_continuous(labels = comma) +  # Format y-axis numbers
theme_minimal()
# Step 6: Check Actual vs Predicted Values
comparison_df <- data.frame(Actual = actual_values, Predicted = predictions_rf)
cat("\nComparison of Actual vs Predicted Values:\n")
print(head(comparison_df))  # Show the first few rows of the comparison
library(rpart.plot)
source("C:/Users/HP/Desktop/carpriceprediciton/XGBoost.R")
# Load necessary libraries
library(GGally)
library(ggplot2)
# Example dataset (replace with your dataset)
df <- mtcars  # Replace with your actual dataset
# Generate the scatterplot matrix
ggpairs(df)
View(data)
View(data)
View(data1)
View(data)
?pairs()
pairs(data=data1,main="frgdfg")
pairs(data1,main="frgdfg")
data1 <- as.data.frame(data1)
pairs(data1,main="frgdfg")
head(data1)
class(data1)
data1 <- read.csv("feature_extraction_data.csv", stringsAsFactors = TRUE)
class(data1)
# Load necessary libraries
library(GGally)
library(ggplot2)
# Generate the scatterplot matrix
ggpairs(data1)
# Load necessary libraries
library(GGally)
library(ggplot2)
# Generate the scatterplot matrix
ggpairs(data1,cardinality_threshold = 40)
# Load necessary libraries
library(GGally)
library(ggplot2)
# Generate the scatterplot matrix
ggpairs(data1,cardinality_threshold = 500)
90
pairs(data1, main = "Scatterplot Matrix")
dev.off()  # Reset the graphics device (in case of any issues)
par(mfrow = c(1,1))  # Reset layout
pairs(data1, main = "Scatterplot Matrix")
par(mar = c(2, 2, 2, 2))  # Reduce margins
pairs(data1, main = "Scatterplot Matrix")
par(data[1,5], main = "Scatterplot Matrix")  # Reduce margins
pairs(data[1,5], main = "Scatterplot Matrix")  # Reduce margins
pairs(data[1:5], main = "Scatterplot Matrix")  # Reduce margins
pairs(encoded_data[1:5], main = "Scatterplot Matrix")  # Reduce margins
pairs(encoded_data[1:12], main = "Scatterplot Matrix")  # Reduce margins
View(encoded_data)
pairs(data[1:12], main = "Scatterplot Matrix")  # Reduce margins
pairs(data1[1:12], main = "Scatterplot Matrix")  # Reduce margins
pairs(data1[1:12], main = "Scatterplot Matrix")  # Reduce margins
View(cleaned_data)
View(cleaned_data)
View(cleaned_data)
